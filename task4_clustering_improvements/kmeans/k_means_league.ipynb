{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a6981e34-50a4-4908-91f6-6c67699a8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics.cluster import v_measure_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "fe4528e2-5f50-4900-9253-555634eaf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def hamming_distance(x, y):\n",
    "    # Calculate the Hamming distance between two strings of equal length\n",
    "    distance = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] != y[i]:\n",
    "            distance += 1\n",
    "    return distance\n",
    "    \n",
    "def kmeans(data, k, max_iterations=10000):\n",
    "    # Initialize centroids with unique random choices from the data\n",
    "    indices = np.random.choice(len(data), k, replace=False)\n",
    "    centroids = [data[i] for i in indices]\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Assign each data point to the nearest centroid\n",
    "        clusters = [[] for i in range(k)]\n",
    "        for point in data:\n",
    "            distances = [hamming_distance(point, centroid) for centroid in centroids]\n",
    "            cluster_index = np.argmin(distances)\n",
    "            clusters[cluster_index] += [point]\n",
    "\n",
    "        new_centroids = []\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            if cluster:\n",
    "                new_centroid = \"\"\n",
    "                for i in range(len(cluster[0])):\n",
    "                    average_bit = int(round(np.mean([int(ohe[i]) for ohe in cluster])))\n",
    "                    new_centroid += str(average_bit)\n",
    "                new_centroids += [new_centroid]\n",
    "            else:\n",
    "                new_centroids += [centroids[i]]\n",
    "\n",
    "        # Check if centroids == new centroids, if new, break\n",
    "        if np.array_equal(centroids, new_centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return centroids, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1c207adf-4175-4ffb-98b3-755a3e699570",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd() + '/db/item_class.json', 'r') as file:\n",
    "    item_list = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "6d8f70b1-3142-4c0d-ae2f-45c2e4a09577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n"
     ]
    }
   ],
   "source": [
    "file_path = './db/league_2.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = [line for line in file]\n",
    "#data is a list of frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a28ae824-2e6a-461a-842b-f8218ae11fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n"
     ]
    }
   ],
   "source": [
    "data = list(filter(lambda x: x!= '\\n', data))\n",
    "for i in range(len(data)):\n",
    "    data[i]= data[i][:-1]\n",
    "data = [json.loads(_) for _ in data]\n",
    "data = [_['items'] for _ in data]\n",
    "#clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "b5ee5146-d025-4012-a7ed-a14a8a0cf8e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate y for each item_set\n",
    "\n",
    "#open the dictionary of item classes\n",
    "file_path = './db/item_class.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    itemmap = json.load(file)\n",
    "\n",
    "y = []\n",
    "for i in x:\n",
    "    dp = {}\n",
    "    res = \"\"\n",
    "    high = 0\n",
    "    for j in i:\n",
    "        if j == '0':\n",
    "            continue\n",
    "        dp[itemmap[j]] = dp.get(itemmap[j], 0) + 1\n",
    "        if dp[itemmap[j]] > high:\n",
    "            res = itemmap[j]\n",
    "            high = dp[itemmap[j]]\n",
    "    y += [res]\n",
    "\n",
    "#now, we want to map to the 311 items\n",
    "x_data = []\n",
    "for itemset in x:\n",
    "    res = \"\"\n",
    "    for i in item_list:\n",
    "        if i not in itemset:\n",
    "            res += \"0\"\n",
    "        else:\n",
    "            res += \"1\"\n",
    "    x_data.append(res)\n",
    "xtoy = {}\n",
    "for i in range(len(x_data)):\n",
    "    #map x to y in a dictionary\n",
    "    xtoy[x_data[i]] = y[i] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bdf945-1ece-4c6d-9f0d-69d57063f10c",
   "metadata": {},
   "source": [
    "# Direct clustering and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e063c08b-64aa-4247-ab68-23193f02cf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n",
      "accuracy:  0.5322997416020672\n",
      "v_measure:  0.26949926974167066\n"
     ]
    }
   ],
   "source": [
    "centroids, clusters = kmeans(x_data, 10)\n",
    "\n",
    "calculate_silhouette_score(centroids, clusters)\n",
    "\n",
    "centroidstoy = {}\n",
    "for i in range(len(centroids)):\n",
    "    dp = {}\n",
    "    high = 0\n",
    "    res = ''\n",
    "    for ohe in clusters[i]:\n",
    "        clas = xtoy[ohe]\n",
    "        dp[clas] = dp.get(clas,0) + 1\n",
    "        if dp[clas] > high:\n",
    "            high = dp[clas]\n",
    "            res = clas\n",
    "    centroidstoy[centroids[i]] = res\n",
    "        \n",
    "\n",
    "# print(centroidstoy)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(centroids)):\n",
    "    for ohe in clusters[i]:\n",
    "        total += 1\n",
    "        if xtoy[ohe] == centroidstoy[centroids[i]]:\n",
    "            correct += 1\n",
    "print(total)\n",
    "\n",
    "\n",
    "\n",
    "real = []\n",
    "predicted = []\n",
    "for i in range(len(clusters)):\n",
    "    for j in clusters[i]:\n",
    "        predicted += [centroidstoy[centroids[i]]]\n",
    "        real += [xtoy[j]]\n",
    "        \n",
    "print('accuracy: ', correct/total)\n",
    "print('v_measure: ', v_measure_score(real, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adceb11-d97e-44f9-bb7c-edf2a85a315a",
   "metadata": {},
   "source": [
    "# Evolving this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3bcea-678f-4d40-a14b-70e00156ef03",
   "metadata": {},
   "source": [
    "## Normalising the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "9ce8306e-bb11-4f60-96b1-d37aa58e9b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fighter': 85, 'Marksman': 55, 'Slayer': 30, 'Controller': 54, 'Tank': 30, 'Specialist': 5, 'Mage': 50, 'Unknown': 2}\n"
     ]
    }
   ],
   "source": [
    "type_count = {}\n",
    "for i in item_list:\n",
    "    clas = item_list[i]\n",
    "    type_count[clas] = type_count.get(clas, 0) + 1\n",
    "print(type_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "dcdd3e7d-3187-49ae-a452-bb7c7708dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate y for each item_set\n",
    "\n",
    "file_path = './db/item_class.json'\n",
    "x_data = x\n",
    "with open(file_path, 'r') as file:\n",
    "    itemmap = json.load(file)\n",
    "y = []\n",
    "for i in x:\n",
    "    dp = {}\n",
    "    res = \"\"\n",
    "    high = 0\n",
    "    for j in i:\n",
    "        if j == '0':\n",
    "            continue\n",
    "        dp[itemmap[j]] = dp.get(itemmap[j], 0) + 1/type_count[itemmap[j]] #item weighted against its rarity\n",
    "        if dp[itemmap[j]] > high:\n",
    "            res = itemmap[j]\n",
    "            high = dp[itemmap[j]]\n",
    "    y += [res]\n",
    "\n",
    "#now, we want to map to the 311 items\n",
    "x_data = []\n",
    "for itemset in x:\n",
    "    res = \"\"\n",
    "    for i in item_list:\n",
    "        if i not in itemset:\n",
    "            res += \"0\"\n",
    "        else:\n",
    "            res += \"1\"\n",
    "    x_data.append(res)\n",
    "xtoy = {}\n",
    "for i in range(len(x_data)):\n",
    "    xtoy[x_data[i]] = y[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "eac80c32-604a-4bb7-837f-9c4ab97e4937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6356589147286822\n",
      "accuracy:  0.6356589147286822\n",
      "v_measure:  0.41200009347113004\n"
     ]
    }
   ],
   "source": [
    "centroids, clusters = kmeans(x_data, 20)\n",
    "\n",
    "calculate_silhouette_score(centroids, clusters)\n",
    "\n",
    "centroidstoy = {}\n",
    "for i in range(len(centroids)):\n",
    "    dp = {}\n",
    "    high = 0\n",
    "    res = ''\n",
    "    for ohe in clusters[i]:\n",
    "        clas = xtoy[ohe]\n",
    "        dp[clas] = dp.get(clas,0) + 1\n",
    "        if dp[clas] > high:\n",
    "            high = dp[clas]\n",
    "            res = clas\n",
    "    centroidstoy[centroids[i]] = res\n",
    "        \n",
    "\n",
    "# print(centroidstoy)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(centroids)):\n",
    "    for ohe in clusters[i]:\n",
    "        total += 1\n",
    "        if xtoy[ohe] == centroidstoy[centroids[i]]:\n",
    "            correct += 1\n",
    "# print(total)\n",
    "\n",
    "print(correct/total)\n",
    "\n",
    "real = []\n",
    "predicted = []\n",
    "for i in range(len(clusters)):\n",
    "    for j in clusters[i]:\n",
    "        predicted += [centroidstoy[centroids[i]]]\n",
    "        real += [xtoy[j]]\n",
    "        \n",
    "\n",
    "print('accuracy: ', correct/total)\n",
    "print('v_measure: ', v_measure_score(real, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad886729-31bb-47ed-949d-c503effdb7a6",
   "metadata": {},
   "source": [
    "## Finding best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "c964850f-af33-4cf9-a28f-b07553a143a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5322997416020672 0.2622813176677009\n",
      "optimal k is: 177 with accuracy 0.9095607235142119 and v_measure 0.7945470213526517\n"
     ]
    }
   ],
   "source": [
    "def k_test(k):\n",
    "    centroids, clusters = kmeans(x_data, k)\n",
    "    \n",
    "    calculate_silhouette_score(centroids, clusters)\n",
    "    \n",
    "    centroidstoy = {}\n",
    "    for i in range(len(centroids)):\n",
    "        dp = {}\n",
    "        high = 0\n",
    "        res = ''\n",
    "        for ohe in clusters[i]:\n",
    "            clas = xtoy[ohe]\n",
    "            dp[clas] = dp.get(clas,0) + 1\n",
    "            if dp[clas] > high:\n",
    "                high = dp[clas]\n",
    "                res = clas\n",
    "        centroidstoy[centroids[i]] = res\n",
    "    \n",
    "    # centroidstoy\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(centroids)):\n",
    "        for ohe in clusters[i]:\n",
    "            total += 1\n",
    "            if xtoy[ohe] == centroidstoy[centroids[i]]:\n",
    "                correct += 1\n",
    "    \n",
    "    # print(\"accuracy: \", correct/total)\n",
    "    \n",
    "    real = []\n",
    "    predicted = []\n",
    "    for i in range(len(clusters)):\n",
    "        for j in clusters[i]:\n",
    "            predicted += [centroidstoy[centroids[i]]]\n",
    "            real += [xtoy[j]]\n",
    "    # print(real)\n",
    "    # print(predicted)\n",
    "    \n",
    "    # print(\"accuracy: \", correct/total)\n",
    "    # print(\"v_measure: \", v_measure_score(real, predicted))\n",
    "    return (correct/total, v_measure_score(real, predicted))\n",
    "\n",
    "accuracy_control, v_measure_control = k_test(10)\n",
    "print(accuracy_control, v_measure_control)\n",
    "best = 10\n",
    "score = v_measure_control\n",
    "optimal = (accuracy_control, v_measure_control)\n",
    "for i in range(2, 200):\n",
    "    accuracy_new, v_measure_new = k_test(i)\n",
    "    gain = (v_measure_new/score)\n",
    "    if gain > 1:\n",
    "        optimal = (accuracy_new, v_measure_new)\n",
    "        best = i\n",
    "        score = v_measure_new\n",
    "print(f'optimal k is: {best} with accuracy {optimal[0]} and v_measure {optimal[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012770f-0557-4f62-88ac-a685d9bb2ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78ac9f-d1f6-4111-b511-6e074662585d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
